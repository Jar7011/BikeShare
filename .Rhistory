mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime)
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.5) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.2) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.7) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(day_and_time = hour*dow) |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.2) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.2) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 10, mixture = 0.2) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.2) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.001, mixture = 0.2) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.1) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_poly(hour, degree = 2) |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.1) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
# Read in training data
bike_training_data <- vroom('train.csv')
# Read in test data
bike_test_data <- vroom('test.csv')
# Clean and tidy up training data
bike_training_data <- bike_training_data |>
select(-casual, -registered)
bike_training_data$season <- factor(bike_training_data$season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))
bike_training_data$weather <- factor(bike_training_data$weather,
levels = c(1,2,3,4))
bike_training_data <- bike_training_data |>
mutate(weather = ifelse(weather == 4, 3, weather))
# Clean and tidy up test data to match training data format
bike_test_data$season <- factor(bike_test_data$season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))
bike_test_data$weather <- factor(bike_test_data$weather,
levels = c(1,2,3,4))
bike_test_data <- bike_test_data |>
mutate(weather = ifelse(weather == 4, 3, weather))
# Some initial EDA plots
glimpse(bike_training_data)
# Read in training data again to reset file
bike_training_data_2 <- vroom('train.csv')
# Read in test data again to reset file
bike_test_data_2 <- vroom('test.csv')
# Eliminate casual and registered columns from training data and
#change count to log(count)
bike_training_data_2 <- bike_training_data_2 |>
select(-casual, -registered) |>
mutate(count = log(count))
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_interact(terms = ~ hour:dow) |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.1) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_interact(terms = ~ hour:dow) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.1) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
?step_interact
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(dow = factor(dow, levels = c(1,2,3,4,5,6,7))) |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_interact(terms = ~ hour:dow) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.1) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
# Create recipe for penalized regression model
penalized_recipe <- recipe(count ~ ., data=bike_training_data_2) |>
step_mutate(weather = ifelse(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather, levels = c(1,2,3))) |>
step_time(datetime, features = 'hour') |>
step_date(datetime, features = 'dow') |>
step_mutate(season = factor(season,
levels = c(1,2,3,4),
labels = c('Spring', 'Summer',
'Fall', 'Winter'))) |>
step_rm(atemp, datetime) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
# Create penalized regression model
penalized_model <- linear_reg(penalty = 0.01, mixture = 0.1) |>
set_engine('glmnet')
penalized_workflow <- workflow() |>
add_recipe(penalized_recipe) |>
add_model(penalized_model) |>
fit(data=bike_training_data_2)
penalized_preds <- predict(penalized_workflow, new_data = bike_test_data_2) |>
mutate(.pred = exp(.pred))
# Format the Predictions for Submission to Kaggle
kaggle_submission <- penalized_preds %>%
bind_cols(., bike_test_data_2) %>% # Bind predictions with test data
select(datetime, .pred) %>% # Just keep datetime and prediction variables
rename(count = .pred) %>% # Rename to count (for submission to Kaggle)
mutate(count = pmax(0, count)) %>% # Pointwise max of (0, prediction)
mutate(datetime = as.character(format(datetime))) # Needed for right format to Kaggle
# Write out the file
vroom_write(x = kaggle_submission, file = "./Penalized_Regression.csv", delim = ",")
